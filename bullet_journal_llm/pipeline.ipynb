{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "This is meant to be a more pipelined version of the `bullet_journal_llm` notebook experiment. This will\n",
    "do bulk extraction of notes from the notebooks, with different prompts based on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing client library\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allen/Development/supernote-llm/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "_LOGGER = logging.getLogger(__name__)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "SECRETS = Path(\"../secrets.yaml\")\n",
    "MODEL_ID = 'gemini-1.5-flash'\n",
    "\n",
    "secrets = yaml.safe_load(SECRETS.read_text())\n",
    "genai.configure(api_key=secrets[\"gemini_api_key\"])\n",
    "\n",
    "_LOGGER.info(\"Initializing client library\")\n",
    "model = genai.GenerativeModel(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTES_DIR = Path(\"../notes\")\n",
    "PAGES_DIR = Path(\"../pages\")\n",
    "DYNAMIC_PROMPTS_DIR = Path(\"dynamic_prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/daily.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/monthly-01.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/rapid_log_legend.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/weekly-02.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/weekly-01.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/monthly-02.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/profile.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/default.yaml\n",
      "INFO:__main__:Loading dynamic prompt: dynamic_prompts/monthly-03.yaml\n"
     ]
    }
   ],
   "source": [
    "from model import DynamicPrompt\n",
    "\n",
    "dynamic_prompts = {}\n",
    "for filename in DYNAMIC_PROMPTS_DIR.glob(\"*.yaml\"):\n",
    "    _LOGGER.info(f\"Loading dynamic prompt: {filename}\")\n",
    "    dynamic_prompts[filename.stem] = DynamicPrompt.from_file(filename)\n",
    "\n",
    "\n",
    "DEFAULT = [\n",
    "    \"default\",\n",
    "    \"rapid_log_legend\",\n",
    "    \"profile\",\n",
    "]\n",
    "FILE_PREFIX_PROMPT_MAP = {\n",
    "    \"Daily\": [\n",
    "        *DEFAULT,\n",
    "        \"daily\",\n",
    "    ],\n",
    "    \"Weekly\": [\n",
    "        *DEFAULT,\n",
    "        \"weekly\",\n",
    "    ],\n",
    "    \"Monthly\": [\n",
    "        *DEFAULT,\n",
    "        \"monthly\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def get_dynamic_prompts(page_filename: Path) -> list[DynamicPrompt]:\n",
    "    \"\"\"Get a set of prompts that match the given prefix\"\"\"\n",
    "\n",
    "    page_name = page_filename.stem\n",
    "    prefix = page_name.split(\"-\")[0]\n",
    "    prompt_names = FILE_PREFIX_PROMPT_MAP.get(prefix, DEFAULT)\n",
    "\n",
    "    prompts = []\n",
    "    for prompt_prefix in prompt_names:\n",
    "        for key, value in dynamic_prompts.items():\n",
    "            if key.startswith(prompt_prefix):\n",
    "                prompts.append(value)\n",
    "    return prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "pages = list(PAGES_DIR.glob(\"*.png\"))\n",
    "# pages_sample = random.sample(pages, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "EXTRACT_JSON = re.compile(\"```json\\n(.*?)\\n```\", re.DOTALL)\n",
    "\n",
    "\n",
    "def parse_model_response(response_text: str) -> str:\n",
    "    \"\"\"Parse the response from the model and return a yaml string.\"\"\"\n",
    "\n",
    "    if response_text.startswith(\"```json\"):\n",
    "        text = EXTRACT_JSON.match(response_text).group(1)\n",
    "    else:\n",
    "        text = response_text\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "    except ValueError as err:\n",
    "        _LOGGER.error(f\"Error processing: %s\", err)\n",
    "        return text\n",
    "    \n",
    "    for k, v in list(obj.items()):\n",
    "        if v is None or v == \"null\":\n",
    "            del obj[k]\n",
    "\n",
    "    return yaml.dump(obj, explicit_start=True, sort_keys=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 30158.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "DOCS = Path(\"../docs\")\n",
    "\n",
    "TIMESTAMP_RE = re.compile(\".*?-\\d+-P(\\d{20}).*.png\")\n",
    "\n",
    "FILE_PROMPT = \"\"\"\n",
    "Please answer in json with no other formatting since the answer will be parsed programmatically.\n",
    "\n",
    "Filename: {filename}\n",
    "Created At: {created_at}\n",
    "Content:\n",
    "\"\"\"\n",
    "\n",
    "for page in tqdm(pages):\n",
    "    re_match = TIMESTAMP_RE.match(str(page))\n",
    "    created_at = datetime.datetime.strptime(re_match.group(1), \"%Y%m%d%H%M%S%f\")\n",
    "\n",
    "    prompts = get_dynamic_prompts(page)\n",
    "    \n",
    "    output_filename = DOCS / f\"{page.stem}.yaml\"\n",
    "    if output_filename.exists():\n",
    "        continue\n",
    "\n",
    "    _LOGGER.info(f\"Generating {output_filename}\")\n",
    "    img = PIL.Image.open(str(page))\n",
    "    prompt = \"\\n\\n\".join([p.as_prompt() for p in prompts])\n",
    "\n",
    "    response = model.generate_content([prompt, FILE_PROMPT.format(filename=f\"{page.stem}.png\", created_at=created_at.isoformat()), img])\n",
    "\n",
    "    output = parse_model_response(response.text)\n",
    "\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        f.write(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from model import JournalPage\n",
    "from mashumaro.exceptions import MissingField\n",
    "\n",
    "DOCS = Path(\"../docs\")\n",
    "\n",
    "for doc_filename in DOCS.glob(\"*.yaml\"):   \n",
    "    text = doc_filename.read_text()\n",
    "    try:\n",
    "        JournalPage.from_yaml(text)\n",
    "    except MissingField as err:\n",
    "        _LOGGER.error(f\"Error processing {doc_filename}: {err}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JournalPage(filename='Future Log-01-P20231219210105181293BAOKeqohWGBJ.png', created_at='2023-12-19T21:01:05.181293', label=None, date=None, content=[{'month': 'APR', 'tasks': [{'type': '>', 'description': 'use marina trip?'}, {'type': '>', 'description': 'yard house $'}, {'type': 'X', 'description': 'Tech Impact Award : 10 before 5/12'}]}, {'month': 'MAY', 'tasks': [{'type': '>', 'description': 'Patio leak review / 1km'}, {'type': '>', 'description': 'use marina trip'}, {'type': '>', 'description': 'yard house $'}, {'type': '•', 'description': 'QQ bytes solved (accuracy)'}, {'type': 'o', 'description': '0509 Teacher PID'}, {'type': 'o', 'description': '0503 - 0505 YD Trip'}, {'type': '•', 'description': 'ETP 0506 - 0521'}]}, {'month': 'JUN', 'tasks': [{'type': 'X', 'description': 'QQ bytes solved (Art)'}, {'type': '•', 'description': 'Patio leak review'}, {'type': '>', 'description': 'marina trip'}, {'type': '>', 'description': 'yard house $'}, {'type': '>', 'description': 'sensitive data loop back'}, {'type': '>', 'description': 'pliny hierarchy'}]}], records=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JournalPage.from_yaml((DOCS / \"Future Log-01-P20231219210105181293BAOKeqohWGBJ.yaml\").read_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
